{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Anomaly Detection Analysis\n",
                "\n",
                "This notebook identifies unusual patterns and operational signals in Aadhaar data.\n",
                "\n",
                "## Methods Used:\n",
                "1. **Z-Score Analysis**: Statistical outlier detection\n",
                "2. **IQR Method**: Interquartile range-based anomalies\n",
                "3. **Time-Series Anomalies**: Unexpected changes in trends\n",
                "4. **Multi-dimensional Analysis**: Combined metric anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from scipy import stats\n",
                "from sklearn.ensemble import IsolationForest\n",
                "\n",
                "print(\"âœ“ Libraries imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('../data/processed/data_with_indicators.csv')\n",
                "df['date'] = pd.to_datetime(df['date'])\n",
                "\n",
                "print(f\"Loaded {len(df):,} records with indicators\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Z-Score Based Anomaly Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate Z-scores for key metrics\n",
                "metrics = ['total_enrolment', 'total_updates', 'update_pressure_index']\n",
                "\n",
                "for metric in metrics:\n",
                "    df[f'{metric}_zscore'] = np.abs(stats.zscore(df[metric].fillna(0)))\n",
                "\n",
                "# Flag anomalies (Z-score > 3)\n",
                "threshold = 3\n",
                "df['is_anomaly'] = (df[[f'{m}_zscore' for m in metrics]].max(axis=1) > threshold)\n",
                "\n",
                "print(f\"\\nðŸ” Anomalies Detected: {df['is_anomaly'].sum():,} ({df['is_anomaly'].mean()*100:.2f}%)\")\n",
                "\n",
                "# Show anomaly distribution by metric\n",
                "for metric in metrics:\n",
                "    anomaly_count = (df[f'{metric}_zscore'] > threshold).sum()\n",
                "    print(f\"  - {metric}: {anomaly_count} anomalies\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Temporal Anomaly Patterns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Anomalies over time\n",
                "daily_anomalies = df.groupby('date')['is_anomaly'].sum().reset_index()\n",
                "daily_anomalies.columns = ['date', 'anomaly_count']\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=daily_anomalies['date'],\n",
                "    y=daily_anomalies['anomaly_count'],\n",
                "    mode='lines+markers',\n",
                "    name='Daily Anomaly Count',\n",
                "    line=dict(color='red', width=2),\n",
                "    marker=dict(size=6)\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Operational Signals (Anomalies) Over Time',\n",
                "    xaxis_title='Date',\n",
                "    yaxis_title='Number of Anomalies',\n",
                "    height=500\n",
                ")\n",
                "\n",
                "fig.show()\n",
                "\n",
                "print(\"\\nðŸ“Š Temporal Pattern:\")\n",
                "print(f\"Peak anomaly date: {daily_anomalies.loc[daily_anomalies['anomaly_count'].idxmax(), 'date']}\")\n",
                "print(f\"Average anomalies per day: {daily_anomalies['anomaly_count'].mean():.1f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Geographic Distribution of Anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# State-wise anomaly count\n",
                "state_anomalies = df[df['is_anomaly']].groupby('state').size().reset_index(name='anomaly_count')\n",
                "state_anomalies = state_anomalies.sort_values('anomaly_count', ascending=False)\n",
                "\n",
                "fig = px.bar(\n",
                "    state_anomalies.head(15),\n",
                "    x='state',\n",
                "    y='anomaly_count',\n",
                "    title='Top 15 States by Operational Signals',\n",
                "    labels={'anomaly_count': 'Number of Signals', 'state': 'State'},\n",
                "    color='anomaly_count',\n",
                "    color_continuous_scale='Oranges'\n",
                ")\n",
                "\n",
                "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Detailed Anomaly Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top anomalies by different metrics\n",
                "print(\"\\nðŸ”´ Top Anomalies by Enrollment:\\n\")\n",
                "top_enrollment_anomalies = df.nlargest(10, 'total_enrolment_zscore')[[\n",
                "    'date', 'state', 'district', 'total_enrolment', 'total_enrolment_zscore'\n",
                "]]\n",
                "print(top_enrollment_anomalies)\n",
                "\n",
                "print(\"\\nðŸ”´ Top Anomalies by Update Pressure Index:\\n\")\n",
                "top_upi_anomalies = df.nlargest(10, 'update_pressure_index_zscore')[[\n",
                "    'date', 'state', 'district', 'update_pressure_index', 'update_pressure_index_zscore'\n",
                "]]\n",
                "print(top_upi_anomalies)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Repeated vs Single Anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Districts with repeated anomalies\n",
                "district_anomaly_freq = df[df['is_anomaly']].groupby(['state', 'district']).size().reset_index(name='frequency')\n",
                "district_anomaly_freq = district_anomaly_freq.sort_values('frequency', ascending=False)\n",
                "\n",
                "print(\"\\nðŸ”´ Districts with Repeated Anomalies (Priority: HIGH):\\n\")\n",
                "repeated_anomalies = district_anomaly_freq[district_anomaly_freq['frequency'] > 1].head(15)\n",
                "print(repeated_anomalies)\n",
                "\n",
                "print(f\"\\nðŸ“Š Summary:\")\n",
                "print(f\"Districts with single anomalies: {(district_anomaly_freq['frequency'] == 1).sum()}\")\n",
                "print(f\"Districts with repeated anomalies: {(district_anomaly_freq['frequency'] > 1).sum()}\")\n",
                "print(f\"Max anomaly frequency: {district_anomaly_freq['frequency'].max()} occurrences\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Isolation Forest (Advanced)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use Isolation Forest for multi-dimensional anomaly detection\n",
                "feature_cols = ['total_enrolment', 'total_updates', 'update_pressure_index']\n",
                "X = df[feature_cols].fillna(0)\n",
                "\n",
                "# Fit Isolation Forest\n",
                "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
                "df['iso_forest_anomaly'] = iso_forest.fit_predict(X)\n",
                "df['iso_forest_anomaly'] = df['iso_forest_anomaly'] == -1\n",
                "\n",
                "print(f\"\\nðŸ¤– Isolation Forest Anomalies: {df['iso_forest_anomaly'].sum():,}\")\n",
                "\n",
                "# Compare methods\n",
                "print(\"\\nðŸ“Š Method Comparison:\")\n",
                "print(f\"Z-Score method: {df['is_anomaly'].sum():,} anomalies\")\n",
                "print(f\"Isolation Forest: {df['iso_forest_anomaly'].sum():,} anomalies\")\n",
                "print(f\"Overlap: {(df['is_anomaly'] & df['iso_forest_anomaly']).sum():,} common anomalies\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Anomaly Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2D visualization of anomalies\n",
                "fig = px.scatter(\n",
                "    df.sample(min(5000, len(df))),  # Sample for performance\n",
                "    x='total_enrolment',\n",
                "    y='total_updates',\n",
                "    color='is_anomaly',\n",
                "    title='Anomaly Detection: Enrollments vs Updates',\n",
                "    labels={'total_enrolment': 'Total Enrollments', 'total_updates': 'Total Updates'},\n",
                "    color_discrete_map={True: 'red', False: 'blue'},\n",
                "    hover_data=['state', 'district', 'update_pressure_index']\n",
                ")\n",
                "\n",
                "fig.update_layout(height=600)\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Operational Insights\n",
                "\n",
                "### Key Findings:\n",
                "\n",
                "1. **Anomaly Frequency**: X% of records flagged as operational signals\n",
                "2. **Geographic Concentration**: Certain states show higher anomaly rates\n",
                "3. **Temporal Patterns**: Anomalies cluster around specific time periods\n",
                "4. **Repeated Signals**: Some districts consistently show unusual patterns\n",
                "\n",
                "### Recommended Actions:\n",
                "\n",
                "**Priority: ðŸ”´ HIGH** (Repeated Anomalies)\n",
                "- Investigate districts with multiple anomaly occurrences\n",
                "- Check for data quality issues or operational irregularities\n",
                "- Deploy additional resources if genuine demand spikes\n",
                "\n",
                "**Priority: ðŸŸ¡ MEDIUM** (Single Anomalies)\n",
                "- Monitor for recurrence\n",
                "- Review operational logs for the anomaly dates\n",
                "- Validate data capture processes\n",
                "\n",
                "**Priority: ðŸŸ¢ LOW** (Machine Learning Detected)\n",
                "- Review Isolation Forest anomalies for subtle patterns\n",
                "- Use for predictive maintenance and planning\n",
                "\n",
                "### Data Quality Note:\n",
                "Anomalies may indicate:\n",
                "- Genuine operational load spikes\n",
                "- Data entry errors\n",
                "- Special events (campaigns, holidays)\n",
                "- System issues\n",
                "\n",
                "**Next Step**: Manual validation required for high-priority anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save anomaly-flagged data\n",
                "df.to_csv('../data/processed/data_with_anomalies.csv', index=False)\n",
                "print(\"\\nâœ… Anomaly detection complete!\")\n",
                "print(\"Data saved to: data/processed/data_with_anomalies.csv\")\n",
                "print(\"\\nNext: Proceed to 05_forecasting.ipynb for predictive modeling\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}